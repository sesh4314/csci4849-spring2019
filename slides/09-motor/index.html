<html>
<head>
<title>Designing for motor disabilities</title>
<style> body { font-family: Helvetica, Arial, sans-serif; margin: 50px; }
.slide { width: 600px; height: 338px;}
.notes { width: 600px;}
.html { width: 580px; min-height: 318px; background: #000; color: #fff; padding: 10px}
.slide, .notes, .html { margin-bottom: 10px;}
.html img { display: none;}
.sr-only { border: 0; clip: rect(0 0 0 0); height: 1px; margin: -1px; overflow: hidden; padding: 0; position: absolute; width: 1px; }
.wrapper { margin: auto; max-width: 600px;}
.slideNumber { font-weight: bold; margin-bottom: 10px; margin-top: 40px; };</style>
</head>
<body>
<div class='wrapper'>
<h1>Designing for motor disabilities</h1>
<div class='content'><div class="row">
<div class="slideNumber">Slide 1</div>
<div class="slide" aria-hidden="true"><img src='images/images.001.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Designing for motor disabilities</h2>
<ul><li>Inclusive Design & Assistive TechnologySpring 2017</li>
</ul>
</div><div class="notes"><p>Image shows two versions of a user interface for selecting a printer. One is the default user interface, and one has large-size buttons for use by a user with a disability. The caption reads "Figure 1. (a) The default interface for a print dialog. (b) A user interface for the print dialog automatically generated for a user with impaired dexterity based on a model of her actual motor capabilities."</p><p>Image from: Krzysztof Z. Gajos, Jacob O. Wobbrock, and Daniel S. Weld. 2008. Improving the performance of motor-impaired users with automatically-generated, ability-based interfaces. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '08). ACM, New York, NY, USA, 1257-1266. DOI=http://dx.doi.org/10.1145/1357054.1357250</p></div></div>
<div class="row">
<div class="slideNumber">Slide 2</div>
<div class="slide" aria-hidden="true"><img src='images/images.002.png' width='600' height='338'></div>
<div class="html sr-only"><h2>This week</h2>
<ul><li>Accessibility for motor impairments</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 3</div>
<div class="slide" aria-hidden="true"><img src='images/images.003.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Designing for motor disabilities</h2>
<ul></ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 4</div>
<div class="slide" aria-hidden="true"><img src='images/images.004.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Designing for motor disabilities</h2>
<ul><li>Understanding types of motor difficulties</li>
<li>Benchmark projects</li>
<li>Strategies for addressing motor challenges</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 5</div>
<div class="slide" aria-hidden="true"><img src='images/images.005.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Understanding motor disability</h2>
<ul><li>Health conditions:</li>
<li>Cerebral palsy, Parkinson's Disease, ALS, traumatic brain injury</li>
<li>Temporary injuries (broken arm, extreme fatigue)</li>
<li> Difficult to design for each condition (they vary greatly)</li>
<li>Instead, focus on functional characteristics</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 6</div>
<div class="slide" aria-hidden="true"><img src='images/images.006.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Functional characteristics</h2>
<ul><li>Reduced range of motion</li>
<li>Inability to make smooth or continuous motions</li>
<li>Inability to pose or gesture properly</li>
<li>Tremor / weakness</li>
<li>Limited fingers / hands / etc</li>
<li>Fatigue / pain</li>
<li>Can affect other aspects of interaction (e.g. dysarthric speech)</li>
<li>Comorbidity with other disabilities (cognitive, vision, etc)</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 7</div>
<div class="slide" aria-hidden="true"><img src='images/images.007.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Common interaction challenges</h2>
<ul><li>Reach</li>
<li>Performing gestures (range of motion may vary)</li>
<li>Bimanual interaction</li>
<li>Fast or repetitive motions</li>
<li>Intelligible speech (because of dysarthric speech)</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 8</div>
<div class="slide" aria-hidden="true"><img src='images/images.008.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Participation restrictions</h2>
<ul><li>Tasks that require dexterity, reach, fast or repetitive motions</li>
<li>May have difficulty juggling multiple tasks or items, retrieving items from the environment</li>
<li>May have difficulty accessing spaces because they are not accessible to a wheelchair or other mobility device)</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 9</div>
<div class="slide" aria-hidden="true"><img src='images/images.009.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Representative users</h2>
<ul><li>Kavita Krishnaswamy (SMA)</li>
<li>Steve Gleason (ALS)</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 10</div>
<div class="slide" aria-hidden="true"><img src='images/images.010.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Kavita Krishnaswamy</h2>
<ul><li>PhD student in computer science at UMBC</li>
<li>Has spinal muscular atrophy</li>
<li>Has movement in head and face, very limited movement in one hand</li>
<li>Often participates via Skype or a telepresence robot</li>
</ul>
</div><div class="notes"><p>Image: Kavita, a young woman wearing glasses, is shown on the screen of a Beam telepresence robot. Image from <a href="https://www.youtube.com/watch?v=oFcDNTb5GPU">Robohub on YouTube</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 11</div>
<div class="slide" aria-hidden="true"><img src='images/images.011.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Using the Beam</h2>
<ul><li>Costs about $10,000 USD</li>
<li>Operated via the browser</li>
<li>Controls for driving the robot, logging in</li>
<li>Requires wifi (so it doesn't work in an elevator!)</li>
</ul>
</div><div class="notes"><p>Image: Screen shot of the Beam user interface which shows three camera views: the robot's "eye level" camera, a camera pointed at the base of the robot, and a webcam view of the robot pilot.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 12</div>
<div class="slide" aria-hidden="true"><img src='images/images.012.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Steve Gleason</h2>
<ul><li>Former pro football player</li>
<li>Diagnosed with ALS at 34</li>
<li>Cannot speak</li>
<li>Limited to eye gaze and some eyebrow movement</li>
</ul>
</div><div class="notes"><p>We'll talk more about Steve Gleason later.</p><p>Image: Steve Gleason, a man sitting in a wheelchair and wearing a ventilator, types on a tablet using eye gaze. Two people stand nearby and follow along with his typing.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 13</div>
<div class="slide" aria-hidden="true"><img src='images/images.013.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Learning about people with motor impairments</h2>
<ul><li>How do we do it?</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 14</div>
<div class="slide" aria-hidden="true"><img src='images/images.014.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Learning about people with motor impairments</h2>
<ul><li>Collaborate with community orgs</li>
<li>Simulation?</li>
<li>Using assistive technology</li>
<li>But how devices are used varies</li>
<li>Learn from online demonstrations</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 15</div>
<div class="slide" aria-hidden="true"><img src='images/images.015.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Participation</h2>
<ul></ul>
</div><div class="notes"><p>Link from <a href="https://www.npr.org/sections/alltechconsidered/2015/01/19/377702882/at-90-shes-designing-tech-for-aging-boomers">NPR</a></p><p>Image: Screen shot of the article shows Barbara Beskind, a 90 year old industral designer.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 16</div>
<div class="slide" aria-hidden="true"><img src='images/images.016.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Participation</h2>
<ul><li>Does the need for representative users on design teams leave others out?</li>
<li>Should only older adults design for older adults?</li>
<li>No! There is always a need for experts in technology and design to translate work from the team, evaluate results</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 17</div>
<div class="slide" aria-hidden="true"><img src='images/images.017.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Simulation</h2>
<ul></ul>
</div><div class="notes"><p>Example of simulation. Link from <a href="http://www.nbcnews.com/id/27200093/ns/business-autos/t/aging-suit-helps-develop-cars-older-drivers/">NBC News</a></p><p>As we discussed before, simulation can help us in learning some things, but</p><p>Image: Screenshot from the article showing a designer wearing the age suit. Blown up text says 'Nissan calls it an aging suit, a cumbersome, strap-on outfit that gives young auto designers the feel of driving with a bulging belly, arthritic joints and shaky balance. The suit Ñ including goggles that distort color and mimic the effects of cataracts Ñ is used to simulate the physical effects of aging as designers work to make future vehicles safer and more comfortable.'</p></div></div>
<div class="row">
<div class="slideNumber">Slide 18</div>
<div class="slide" aria-hidden="true"><img src='images/images.018.png' width='600' height='338'></div>
<div class="html sr-only"><h2>User-generated content</h2>
<ul><li>People often share their experiences online</li>
<li>YouTube/blogs, online communities for a certain condition, help or tech support forumsÉ</li>
</ul>
</div><div class="notes"><p>Lisa Anthony, YooJin Kim, and Leah Findlater. 2013. Analyzing user-generated youtube videos to understand touchscreen use by people with motor impairments. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI '13). ACM, New York, NY, USA, 1223-1232. DOI: https://doi.org/10.1145/2470654.2466158</p><p>Image: Screen shot of the article shows one person holding a smartphone with a hand prosthetic hook, and a person using their nose to control a smartphone mounted in front of their face.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 19</div>
<div class="slide" aria-hidden="true"><img src='images/images.019.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Assistive technology for motor disabilities</h2>
<ul></ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 20</div>
<div class="slide" aria-hidden="true"><img src='images/images.020.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Improving computer access: strategies</h2>
<ul><li>Replace complex interactions with simple interactions</li>
<li>Use hardware that helps prevent errors</li>
<li>Use software to detect and reduce errors</li>
<li>Alter existing interfaces to be more accessible</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 21</div>
<div class="slide" aria-hidden="true"><img src='images/images.021.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Assistive technologies: software</h2>
<ul><li>Mouse keys - use keys to move mouse cursor</li>
<li>Sticky keys - make shift, alt, control modal - press once to toggle mode</li>
<li>Filter keys - remove repeated keys if the key is held down for too long</li>
</ul>
</div><div class="notes"><p>Alternative keyboards, keyboard layouts Remember, mouse keys is very different than using a mouse, may be very inefficient Shaun uses stickykeys most of the time</p></div></div>
<div class="row">
<div class="slideNumber">Slide 22</div>
<div class="slide" aria-hidden="true"><img src='images/images.022.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Assistive pointing</h2>
<ul><li>Seems like the Bubble Cursor and similar techniques would help</li>
<li>So why don't we use them?</li>
</ul>
</div><div class="notes"><p>Image: Screen shot of a slide describing the Bubble Cursor. It says "A simple algorithm. Continuously updates the radius of the bubble. Minimum distance betwen: furthest point of the closest target. Nearest point of the second closest." Image from <a href="https://www.slideshare.net/franzonadiman/the-bubble-cursor">Francesco Bonadiman on SlideShare</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 23</div>
<div class="slide" aria-hidden="true"><img src='images/images.023.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Where design meets reality</h2>
<ul><li>The bubble cursor is pointer-aware</li>
<li>Requires that the application knows where each target is; must be able to control either the pointer or change the UI layout</li>
<li>Many interesting accessibility systems cannot easily be implemented in the real-world due to OS limitations</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 24</div>
<div class="slide" aria-hidden="true"><img src='images/images.024.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Can we help pointing?</h2>
<ul><li>Identify possible errors using heuristic methods or machine learning</li>
<li>Example: Steady Clicks (Trewin et al., ASSETS '06)</li>
<li>Some users consistently slip after clicking the mouse button</li>
<li>Detect if the cursor moves between mouse down and mouse up; if so, put it back at the mouse down location</li>
<li>Doesn't require knowledge of the underlying UI</li>
</ul>
</div><div class="notes"><ul><li><a href="https://dl.acm.org/citation.cfm?id=1168993">Steady Clicks paper</a></li></ul></div></div>
<div class="row">
<div class="slideNumber">Slide 25</div>
<div class="slide" aria-hidden="true"><img src='images/images.025.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Physical adaptations</h2>
<ul><li>Keyguards</li>
<li>Switch control</li>
<li>Head mouse</li>
<li>Eye trackers (more next week)</li>
<li>Physical pointers / styli</li>
<li>Using other body parts / poses</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 26</div>
<div class="slide" aria-hidden="true"><img src='images/images.026.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Keyguard</h2>
<ul><li>Physically constrains movements between keys</li>
<li>Drawbacks: expensive, fragile, difficult to transport, can't use your buddy's device</li>
</ul>
</div><div class="notes"><p>Image: A keyguard, which is a thin sheet of plastic that is placed over a keyboard, and has cutouts for each key. This prevents the user from sliding her fingers from one key to another. Image from <a href="http://salestores.com/stores/images/images_747/CHESTERCREEKKG.jpg">salestores</a></p><p>This is, in many ways, considered the "old way" of thinking.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 27</div>
<div class="slide" aria-hidden="true"><img src='images/images.027.png' width='600' height='338'></div>
<div class="html sr-only"><h2>An "invisible keyguard"</h2>
<ul><li>Detect error-like movements and correct them</li>
</ul>
</div><div class="notes"><p>Shari Trewin. 2002. An invisible keyguard. In Proceedings of the fifth international ACM conference on Assistive technologies (Assets '02). ACM, New York, NY, USA, 143-149. DOI=http://dx.doi.org/10.1145/638249.638275</p><p>Image is a screenshot from the paper.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 28</div>
<div class="slide" aria-hidden="true"><img src='images/images.028.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Head mice</h2>
<ul><li>Can use a reflective dot on the head or track face</li>
<li>May use infrared cam (with an IR-reflective dot) or webcam</li>
<li>Interaction challenges?</li>
<li>Speed vs. accuracy tradeoff (gain)</li>
<li>Midas touch problem</li>
<li>Field of vision</li>
</ul>
</div><div class="notes"><p>You can find free head mouse software at <a href="http://www.cameramouse.org">CameraMouse.org</a></p><p>Image: Woman using a head mouse. She has a reflective dot on her head and the head mouse camera is mounted above her computer screen. Image from <a href="https://www.youtube.com/watch?v=c_45Q1aQDWQ">North Bristol NHS Trust via YouTube</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 29</div>
<div class="slide" aria-hidden="true"><img src='images/images.029.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Eye tracker</h2>
<ul><li>Infrared camera tracks movement of pupils</li>
<li>Useful when head mouse is not possible</li>
<li>Similar challenges to head mouse, but may be even less accurate</li>
</ul>
</div><div class="notes"><p>Image: A woman using an eye tracker on her computer monitor. Image from <a href="http://www.tobiipro.com/product-listing/tobii-pro-x3-120/">Tobii</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 30</div>
<div class="slide" aria-hidden="true"><img src='images/images.030.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Physical pointers</h2>
<ul><li>Can be attached to various parts of the body</li>
<li>Can support different end effectors</li>
<li>May require capacitance, pressure, etc</li>
</ul>
</div><div class="notes"><p>Image: Man in a wheelchair using a head pointer to interact with a tablet that is mounted on his chair. Image from <a href="https://www.rjcooper.com/tablet-headpointer/index.html">RJ Cooper</a></p><p>How these work depends on what is being controlled.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 31</div>
<div class="slide" aria-hidden="true"><img src='images/images.031.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Alternative poses / body parts</h2>
<ul><li>May be unable to form certain hand shapes</li>
<li>Can be a problem for multi-finger and whole-hand gestures</li>
<li>Range of motion may be very different</li>
</ul>
</div><div class="notes"><p>Image: Four images showing different hand grips when using a touchpad.</p><p>Patrick Carrington, Amy Hurst, and Shaun K. Kane. 2014. The gest-rest: a pressure-sensitive chairable input pad for power wheelchair armrests. In Proceedings of the 16th international ACM SIGACCESS conference on Computers &amp; accessibility (ASSETS '14). ACM, New York, NY, USA, 201-208. DOI: http://dx.doi.org/10.1145/2661334.2661374</p></div></div>
<div class="row">
<div class="slideNumber">Slide 32</div>
<div class="slide" aria-hidden="true"><img src='images/images.032.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Using other body parts</h2>
<ul><li>May have limited range of motion, strength, visibility</li>
<li>Other concerns depending on the body part (e.g. can't see when you're pointing with your nose)</li>
</ul>
</div><div class="notes"><p>Image: Person using their nose to interact with a smartphone. Image from Lisa Anthony et al., <a href="https://doi.org/10.1145/2470654.2466158">Analyzing user-generated youtube videos to understand touchscreen use by people with motor impairments.</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 33</div>
<div class="slide" aria-hidden="true"><img src='images/images.033.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Switch control</h2>
<ul><li>These are really just buttons + software to control traditional user interfaces</li>
<li>May be placed in various places (near hands, head, etc.)</li>
<li>Multiple actuation methods depending on type (e.g. firm or light pressure, proximity)</li>
</ul>
</div><div class="notes"><p>Images: Top: Man in a wheelchair using switches to control his iPhone. Video from <a href="https://www.youtube.com/watch?v=ykvY4lMDytU">YouTube</a>. Bottom: Four brightly colored switch buttons. Image from <a href="http://www.uscomputersinc.com/sites/default/files/JellyBean-twist.png">US Computers</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 34</div>
<div class="slide" aria-hidden="true"><img src='images/images.034.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Designing switch interfaces</h2>
<ul><li>What to do with only N keys?</li>
<li>5 keys: 4 directions + select</li>
<li>3 keys: previous, next + select</li>
<li>2 keys: next + select</li>
<li>1 key: ????</li>
</ul>
</div><div class="notes"><h3 id="images">Images</h3><p>Top: Woman using a Sip and Puff device to control an iPad. Image from <a href="https://gettecla.com/blogs/news/15538916-what-is-switch-control-mode-in-apples-ios">Tecla</a>. With a sip and puff, the user can suck in air, blow out, and move the straw like a joystick. - Bottom: Woman using a single switch to control iOS. Image from <a href="https://www.youtube.com/watch?v=TH540kuBDwo">Jane Farrall via YouTube</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 35</div>
<div class="slide" aria-hidden="true"><img src='images/images.035.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Single switch access</h2>
<ul><li>Use a scanning user interface</li>
<li>Cursor moves between controls at a timed interval</li>
<li>Press to select the current item</li>
<li>May pop-up a menu if multiple input methods are available (e.g. left vs right mouse button, gestures)</li>
</ul>
</div><div class="notes"><p>Image: iPad has two switch buttons controlled via Bluetooth. The iPad's screen is showing a calculator app, which is currently highlighting the 8 key. Image is from <a href="https://www.youtube.com/watch?v=SnDA2pbBsTQ">Pretorian Technologies via YouTube</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 36</div>
<div class="slide" aria-hidden="true"><img src='images/images.036.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Scanning Ambiguous Keyboards</h2>
<ul><li>Use language model topredict what the user iswriting (and give them backup choices)</li>
<li>Trade-off between number of keys and quality of guess</li>
<li>Can formally optimize number of buttons for the user / # of switch controls</li>
</ul>
</div><div class="notes"><p>Image: Scanning Ambiguous Keyboard from <a href="http://www.yorku.ca/mack/bhci2017.html">Scot MacKenzie</a>. Image shows a Java application with four keys, three each showing one third of the alphabet and one showing space.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 37</div>
<div class="slide" aria-hidden="true"><img src='images/images.037.png' width='600' height='338'></div>
<div class="html sr-only"><h2>AT examples from research</h2>
<ul><li>EdgeWrite</li>
<li>TrueKeys</li>
<li>Gest Rest</li>
<li>Smart Touch</li>
<li>SUPPLE++</li>
<li>VoiceDraw</li>
<li>3D printed prosthetics and grips</li>
</ul>
</div><div class="notes"><p>These examples focus on different strategiesÉ</p></div></div>
<div class="row">
<div class="slideNumber">Slide 38</div>
<div class="slide" aria-hidden="true"><img src='images/images.038.png' width='600' height='338'></div>
<div class="html sr-only"><h2>EdgeWrite [Wobbrock et al. 2003]</h2>
<ul><li>Stylus-based text entry for people with motor difficulties</li>
<li>Uses physical template over writing area to steady hand</li>
<li>Uses modified stroke alphabet to reduce requirement for straight lines</li>
<li>4-corner recognizer supported on many devices (stylus, trackball, joystick, touch screen)</li>
</ul>
</div><div class="notes"><p>Image: EdgeWrite prototype shows a clear plastic overlay over a PDA, with a square cut out for writing within. Image from <a href="https://faculty.washington.edu/wobbrock/">Jacob Wobbrock</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 39</div>
<div class="slide" aria-hidden="true"><img src='images/images.039.png' width='600' height='338'></div>
<div class="html sr-only"><h2></h2>
<ul></ul>
</div><div class="notes"><p>Image: EdgeWrite character set. All characters are written based on strokes along the edges of the physical template.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 40</div>
<div class="slide" aria-hidden="true"><img src='images/images.040.png' width='600' height='338'></div>
<div class="html sr-only"><h2>TrueKeys [Kane et al. 2008]</h2>
<ul><li>Custom spelling corrector for people with motor difficulties</li>
<li>Recognizes common errors for that specific user</li>
<li>Let the user type normally; make the system sort it out</li>
</ul>
</div><div class="notes"><p>Image: a user is typing in a text box, and a correction window has popped up.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 41</div>
<div class="slide" aria-hidden="true"><img src='images/images.041.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Smart Touch [Mott et al. 2016] </h2>
<ul><li>Recognize alternative hand placements on the touch screen</li>
<li>Allows the user to train a touch point, even if they physically can't make one</li>
</ul>
</div><div class="notes"><p>Image: A person places their hand on the touch screen, but they are resting their whole hand rather than pointing a finger. The system is recognizing their touch contacts and predicting their intended touch point.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 42</div>
<div class="slide" aria-hidden="true"><img src='images/images.042.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Goal crossing [Wobbrock and Gajos 2007]</h2>
<ul><li>Pointing at and clicking a target can be difficult for some users</li>
<li>Instead, set a goal that the user can drive the cursor through</li>
</ul>
</div><div class="notes"><p>Image: A goal-crossing based UI requires that the mouse pass through the goal, rather than clicking in a region.</p><p>In goal crossing, the target is a line rather than a rectangle. This suggests a fundamental shift in how we design the user interface!</p></div></div>
<div class="row">
<div class="slideNumber">Slide 43</div>
<div class="slide" aria-hidden="true"><img src='images/images.043.png' width='600' height='338'></div>
<div class="html sr-only"><h2>How to design goal crossing interfaces?</h2>
<ul><li>Difficult to adapt to existing UIs</li>
<li>Targets are line segments, not rectangles!</li>
</ul>
</div><div class="notes"><p>Citation: Leah Findlater et al., <a href="https://faculty.washington.edu/wobbrock/pubs/uist-10.pdf">Enhanced Area Cursors: Reducing fine pointing demands for people with motor impairments</a>, UIST 2010</p><p>Image: Screen shot of enhanced area cursors from the paper</p></div></div>
<div class="row">
<div class="slideNumber">Slide 44</div>
<div class="slide" aria-hidden="true"><img src='images/images.044.png' width='600' height='338'></div>
<div class="html sr-only"><h2>CrossY [Apitz and Giumbretiere 2004]</h2>
<ul><li>Not designed for users with disabilities, but for pen tablet users</li>
<li>All interactions involve crossing without clicking</li>
</ul>
</div><div class="notes"><p>Image: Screenshot of CrossY, a drawing tool. Link: <a href="http://www.cs.umd.edu/hcil/crossy/">CrossY</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 45</div>
<div class="slide" aria-hidden="true"><img src='images/images.045.png' width='600' height='338'></div>
<div class="html sr-only"><h2>SUPPLE++ [Gajos et al. 2008]</h2>
<ul><li>Use performance to tailor user interface</li>
<li>Adjust button size, spacing, etc.</li>
<li>Disability agnostic; based entirely on performance</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 46</div>
<div class="slide" aria-hidden="true"><img src='images/images.046.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Gest Rest [Carrington et al. 2014]</h2>
<ul><li>Integrate input into wheelchair itself</li>
<li>Array of pressure sensors in a textile cover</li>
<li>Use pressure-based gestures to support wide range of interactions</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 47</div>
<div class="slide" aria-hidden="true"><img src='images/images.047.png' width='600' height='338'></div>
<div class="html sr-only"><h2>VoiceDraw [Harada et al. 2007]</h2>
<ul><li>Voice based interface that uses non-speech vowel sounds</li>
<li>Use voice as an expressive input mode (use available variables - tone, volume)</li>
<li>Video: https://www.youtube.com/watch?v=qHLHoe6_-L8</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 48</div>
<div class="slide" aria-hidden="true"><img src='images/images.048.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Tongue-drive wheelchair</h2>
<ul><li>Track with metallic tongue stud, smart retainer, or ultrasonic waves</li>
<li>Extremely useful for paralyzed people</li>
</ul>
</div><div class="notes"><p>Video link: <a href="https://www.youtube.com/watch?v=KZHBNYd-eWs">Georgia Tech Tongue Drive System</a></p><p>Image: A man is wearing a headset and moving his tongue to drive a wheelchair.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 49</div>
<div class="slide" aria-hidden="true"><img src='images/images.049.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Brain Controlled Interfaces (BCIs)</h2>
<ul><li>Typically use EEG headsets (other methods are much more invasive)</li>
<li>Limited range of input - typically one or very few signals possible</li>
<li>Can be combined with a scanning-based UI</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 50</div>
<div class="slide" aria-hidden="true"><img src='images/images.050.png' width='600' height='338'></div>
<div class="html sr-only"><h2>NeuroPhone [Campbell et al. 2010]</h2>
<ul><li>EEG-based mobile phone dialer </li>
<li>Relatively limited signal from brain without going inside the skull</li>
<li>So, uses scanning interface</li>
</ul>
</div><div class="notes"><p>Images: Top: man sitting on bench using a phone. Bottom: Image of the NeuroPhone interface shows 6 photos. This is a scanning-based interface. The user can concentrate to dial the number of the currently highlighted person.</p><p>Video from <a href="https://www.youtube.com/watch?v=tc82Z_yfEwc">Matt Mukerjee via YouTube</a></p></div></div>
<div class="row">
<div class="slideNumber">Slide 51</div>
<div class="slide" aria-hidden="true"><img src='images/images.051.png' width='600' height='338'></div>
<div class="html sr-only"><h2>3D printing for motor disabilities</h2>
<ul><li>3D printed prosthetics from e-NABLE project</li>
<li>Customized 3D printed pen grip</li>
</ul>
</div><div class="notes"><p>Erin Buehler et al., <a href="https://dl.acm.org/citation.cfm?id=2661345">GripFab</a></p><p>Images: Top: a young boy has a 3D printed hand designed to look like Wolverine's claws. Bottom: a 3D-printed grip for a stylus, designed to perfectly fit the user's grip.</p></div></div>
<div class="row">
<div class="slideNumber">Slide 52</div>
<div class="slide" aria-hidden="true"><img src='images/images.052.png' width='600' height='338'></div>
<div class="html sr-only"><h2>Takeaways</h2>
<ul><li>Consider alternative uses for existing devices</li>
<li>Identify the user's ability, range of motion (even from unexpected places)</li>
<li>Design gesture or command set to match</li>
</ul>
</div><div class="notes"></div></div>
<div class="row">
<div class="slideNumber">Slide 53</div>
<div class="slide" aria-hidden="true"><img src='images/images.053.png' width='600' height='338'></div>
<div class="html sr-only"><h2>For next time</h2>
<ul><li>We'll design interfaces for switch control</li>
</ul>
</div><div class="notes"></div></div>
</div>
</div>
</body>
</html>